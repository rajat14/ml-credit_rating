{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1d0c58b8",
      "metadata": {
        "id": "1d0c58b8"
      },
      "source": [
        "### Load the necessary libraries and modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bc4ef2",
      "metadata": {
        "id": "43bc4ef2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import (\n",
        "    SelectKBest, f_classif, chi2, mutual_info_classif,\n",
        "    RFE, RFECV, SelectFromModel, VarianceThreshold\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression, LassoCV\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a6b9e9",
      "metadata": {
        "id": "41a6b9e9"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad597b0",
      "metadata": {
        "id": "1ad597b0"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "- The data has 100 rows and 154 columns with 151 numerical columns, 1 categorical column(RATING_TYPE), 1 unstructured data column(string_values) and 1 categorical with order column(Rating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1506195",
      "metadata": {
        "id": "c1506195"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://github.com/Banking-Analytics-Lab/MultimodalFusionRatings/blob/main/Data/Artificial_Data.xlsx?raw=true\"\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "df_1 = pd.read_excel(data_url)\n",
        "\n",
        "print(\"dataset is loaded successfully.\\n\")\n",
        "\n",
        "# checking first five rows of the data\n",
        "\n",
        "print(df_1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc083af8",
      "metadata": {
        "id": "bc083af8"
      },
      "outputs": [],
      "source": [
        "# Inspecting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13dacbca",
      "metadata": {
        "id": "13dacbca"
      },
      "source": [
        "# Extract the columns and data types\n",
        "- 151 numerical columns belongs to 'float64' dtype while the remaining categorical and text colums are objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c03668c0",
      "metadata": {
        "id": "c03668c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "col_data_types = df_1.dtypes\n",
        "print(f\"The data types of the columns are:\\n\\n{col_data_types}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5973ac",
      "metadata": {
        "id": "ac5973ac"
      },
      "source": [
        "# Basic descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c16bf3",
      "metadata": {
        "id": "01c16bf3"
      },
      "outputs": [],
      "source": [
        "print(f\"Descriptive Stats for the dataframe:\\n\\n{df_1.describe()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5346bd",
      "metadata": {
        "id": "3c5346bd"
      },
      "source": [
        "# Observations based on the data description\n",
        "- Based on the descriptive stats, it seems the data is more or less pre-processed and doesn't have any significant outliers. The standard deviation for majority of the columns are with in +1SD. Min and Max values are b/w -3 to 3. So, the scaling of the variables is already done in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e987cb68",
      "metadata": {
        "id": "e987cb68"
      },
      "outputs": [],
      "source": [
        "# We will check for outliers in the columns to understand the data quality.\n",
        "for col in df_1.select_dtypes(include='float64').columns:\n",
        "    Q1 = df_1[col].quantile(0.25)\n",
        "    Q3 = df_1[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = df_1[(df_1[col] < lower_bound) | (df_1[col] > upper_bound)]\n",
        "\n",
        "    print(f\"\\nOutliers in column '{col}':\")\n",
        "    print(outliers[[col]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179bb1e7",
      "metadata": {
        "id": "179bb1e7"
      },
      "source": [
        "# Understanding the proprotion of the outliers in each column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242529c9",
      "metadata": {
        "id": "242529c9"
      },
      "outputs": [],
      "source": [
        "outlier_perc = {}\n",
        "\n",
        "for col in df_1.select_dtypes(include='float64').columns:\n",
        "\n",
        "    Q1 = df_1[col].quantile(0.25)\n",
        "    Q3 = df_1[col].quantile(0.75)\n",
        "\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    l_outlier = len(df_1.loc[(df_1[col] < lower_bound)  ,col])\n",
        "    u_outlier = len(df_1.loc[(df_1[col] > upper_bound)  ,col])\n",
        "\n",
        "    outlier_count = l_outlier + u_outlier\n",
        "\n",
        "    percentage_outlier = outlier_count * 100/len(df_1)\n",
        "\n",
        "\n",
        "    outlier_perc[col] = percentage_outlier\n",
        "\n",
        "    print(f\"{col}:{(percentage_outlier)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4f511c7",
      "metadata": {
        "id": "b4f511c7"
      },
      "source": [
        "# Distribution of outlier percentage across the data\n",
        "- Except for one variable which have 5% and 7 variables which have 3% outliers,\n",
        "the remianing variables are well with in the tolerance limit. So, outliers are not creating any major issues in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd60583",
      "metadata": {
        "id": "bfd60583"
      },
      "outputs": [],
      "source": [
        "\n",
        "outlier_series = pd.Series(outlier_perc).sort_values(ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "outlier_series.plot(kind='bar', color='salmon', edgecolor='black')\n",
        "plt.ylabel(\"Outlier Percentage\")\n",
        "plt.title(\"Outlier Percentage by Column\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccbd2ba5",
      "metadata": {
        "id": "ccbd2ba5"
      },
      "source": [
        "# Check for missing values\n",
        "\n",
        "- There are no missing values in the data. The data seems ideal which is not the case usually in real world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366e00ea",
      "metadata": {
        "id": "366e00ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"\\nMissing Values:\")\n",
        "missing_data = df_1.isnull().sum()\n",
        "missing_perc = (missing_data / len(df_1)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'missing_count': missing_data,\n",
        "    'missing_percentage': missing_perc\n",
        "})\n",
        "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values('missing_count', ascending=False)\n",
        "print(missing_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a505fc6",
      "metadata": {
        "id": "6a505fc6"
      },
      "source": [
        "# Check Skewness in the data\n",
        "- As per the stats of the data skewness, the data is fairly symmetric and therefore requires no intervention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd5c2c5",
      "metadata": {
        "id": "9fd5c2c5"
      },
      "outputs": [],
      "source": [
        "skew_data = df_1.select_dtypes(include='float64').skew().sort_values(ascending=False)\n",
        "\n",
        "print(f\"The skew data is:\\n{skew_data.describe()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e68bb6",
      "metadata": {
        "id": "46e68bb6"
      },
      "source": [
        "# correlation matrix\n",
        "- No pairs are highly correlated as analysed by setting up a threshold of 0.9. Therefore, there is no strong relationship among the features.\n",
        "- There are 0 high correlation pairs as analysed below. Changing the threshold to 0.4 results in 2 pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6853f053",
      "metadata": {
        "id": "6853f053"
      },
      "outputs": [],
      "source": [
        "corr_df = df_1.select_dtypes(include='float64').corr()\n",
        "\n",
        "# create correlation matrix as a dataframe\n",
        "corr_matrix = pd.DataFrame(corr_df)\n",
        "\n",
        "#print(corr_matrix.head())\n",
        "\n",
        "# Set a threshold\n",
        "threshold = 0.9\n",
        "\n",
        "# Find correlated pairs above the threshold\n",
        "high_corr = (corr_df.abs() > threshold) & (corr_df.abs() < 1.0)\n",
        "\n",
        "# Extract the column pairs\n",
        "high_corr_pairs = []\n",
        "\n",
        "for col in high_corr.columns:\n",
        "    corr_features = high_corr.index[high_corr[col]].tolist()\n",
        "\n",
        "    for row in corr_features:\n",
        "        if (row, col) not in high_corr_pairs and (col, row) not in high_corr_pairs:\n",
        "            high_corr_pairs.append((row, col))\n",
        "\n",
        "\n",
        "# Print the pairs and their correlation values\n",
        "for row, col in high_corr_pairs:\n",
        "    print(f\"{row} ↔ {col} : correlation = {corr_df.loc[row, col]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e746ba",
      "metadata": {
        "id": "56e746ba"
      },
      "source": [
        "# visualize correlation features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e7c312",
      "metadata": {
        "id": "97e7c312"
      },
      "outputs": [],
      "source": [
        "# Step 3: Visualize it as a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_df, cmap='coolwarm', center=0, annot=False, fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix of Numeric Columns\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e17276",
      "metadata": {
        "id": "21e17276"
      },
      "source": [
        "# Target Variable Selection\n",
        "- Based on the analysis of the data, the target variable will be 'Rating'. The 'RATING_TYPE' variable which represents rating agencies can be used if the rating agencies will have different 'Rating' standards. But, in this data, the ratings of each rating agencies are of the same type. If they would have been different where Moody's have different rating scale as compared to S&P's and Fitch, then we would have chosen a new variable- 'Risk_Scale' as the target variable to eliminate the subjectivity of the rating agencies using a matrix mapping of the different rating agencies.\n",
        "But since the data consists of same rating standard for all the 3 rating agenceis, it doesn't need a new target variable. We will convert the 'Rating' to numeric rating after mapping the original rating to a risk scale."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33ced363",
      "metadata": {
        "id": "33ced363"
      },
      "source": [
        "# Feature Selection\n",
        "- Based on the target variable, correlation and the domain knowledg, the feature variables will be the financial ratios and unstructured text as present in the data.\n",
        "The rest of the ratios are not important considering that the company credit rating is dependent on the financial information. The stock index, bond index returns are important when the target variable would have been 'Future_Performance'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e409ebe3",
      "metadata": {
        "id": "e409ebe3"
      },
      "outputs": [],
      "source": [
        "# Taking only financial rations as structured variables as the other like index returns/bond market returns are not\n",
        "#important\n",
        "structured_cols = ['bm','evm','pe_op_basic','pe_op_dil','pe_exi','pe_inc','ps','pcf','npm','opmbd','opmad','gpm','ptpm','cfm','roa','roe','roce','aftret_eq','aftret_invcapx','aftret_equity','GProf','equity_invcap','debt_invcap','totdebt_invcap','capital_ratio','cash_lt','debt_at','debt_ebitda','lt_debt','cash_debt','lt_ppent','dltt_be','debt_assets','debt_capital','de_ratio','at_turn','rect_turn','pay_turn','sale_invcap','sale_equity','rd_sale','adv_sale','staff_sale','accrual'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abd9909",
      "metadata": {
        "id": "3abd9909"
      },
      "outputs": [],
      "source": [
        "# New dataframe with Target Variable as Rating, financial ratios as structured ratios and\n",
        "#string values as unstructured(text) variable\n",
        "\n",
        "df = df_1[['Rating'] + structured_cols + ['string_values']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d45749",
      "metadata": {
        "id": "a1d45749"
      },
      "source": [
        "# Encode the 'Rating' Variable to numerical rating for modelling\n",
        "- Since the rating has inherent order and in business, it is interpreted as a symbol of risk measurement, it is essential to map them to risk and then to a numeric value.\n",
        "- Since we only have ratings from AAA to BB, we are mapping them from Lowest Risk to Highest Risk. The Highest Risk should not be taken in literal sense as the highest risk usaully occurs for C and below Rating.\n",
        "- For eg: AAA is the highest rating and lowest risk. The jump b/w AAA and the second best rating AA+ is different than the jump b/w AA+ and AA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3718f648",
      "metadata": {
        "id": "3718f648"
      },
      "outputs": [],
      "source": [
        "rating_to_risk = {\n",
        "                'AAA': 'Lowest Risk',\n",
        "                'AA+': 'Low Risk',\n",
        "                'AA': 'Low Risk',\n",
        "                'A+': 'Medium Risk',\n",
        "                'A': 'Medium Risk',\n",
        "                'BBB+': 'High Risk',\n",
        "                'BBB': 'Highest Risk',\n",
        "                'BB': 'Highest Risk'\n",
        "            }\n",
        "\n",
        "# Risk category to numerical mapping (ordered by risk level)\n",
        "risk_to_numeric = {\n",
        "    'Lowest Risk': 0,\n",
        "    'Low Risk': 1,\n",
        "    'Medium Risk': 2,\n",
        "    'High Risk': 3,\n",
        "    'Highest Risk': 4,\n",
        "    'In Default': 5\n",
        "}\n",
        "\n",
        "# for rating column, map it to risk category\n",
        "if 'Rating' in df.columns:\n",
        "    print(\"Converting credit ratings to risk categories...\")\n",
        "\n",
        "    # Convert credit rating to risk category\n",
        "    risk_cat = df['Rating'].map(rating_to_risk)\n",
        "\n",
        "    # Now convert risk category to numeric\n",
        "    rating_numeric = risk_cat.map(risk_to_numeric)\n",
        "\n",
        "   # Credit Rating -> Risk Category -> Numerical Mapping\n",
        "    for rating, risk in rating_to_risk.items():\n",
        "        numeric = risk_to_numeric[risk]\n",
        "        print(f\"  {rating:>3} -> {risk:<12} -> {numeric}\")\n",
        "\n",
        "   # Target distribution after encoding\n",
        "    risk_counts = risk_cat.value_counts()\n",
        "    numeric_counts = pd.Series(rating_numeric).value_counts().sort_index()\n",
        "\n",
        "    for risk_cat, count in risk_counts.items():\n",
        "        numeric_val = risk_to_numeric[risk_cat]\n",
        "        print(f\"  {risk_cat:<12} ({numeric_val}): {count:>4} samples\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c61b555",
      "metadata": {
        "id": "2c61b555"
      },
      "source": [
        "# Distribution of Target Variable\n",
        "- The distribution reflects that the samples are not severly imbalanced. Numeric Rating with 0 & 3\n",
        "have 10 samples each and Numeric Rating with 1, 2 & 4 have 25,26 and 29 samples respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0d7b7e",
      "metadata": {
        "id": "ca0d7b7e"
      },
      "outputs": [],
      "source": [
        "# Plot distribution of risk categories\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=risk_counts.index, y=risk_counts.values, palette=\"Blues_d\")\n",
        "plt.title(\"Distribution of Risk Categories\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.xlabel(\"Risk Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot distribution of encoded numeric risk\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=numeric_counts.index.astype(str), y=numeric_counts.values, palette=\"Oranges_d\")\n",
        "plt.title(\"Distribution of Encoded Risk (Numeric)\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.xlabel(\"Encoded Risk Level\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b86b61",
      "metadata": {
        "id": "c1b86b61"
      },
      "outputs": [],
      "source": [
        "# Replace the original 'Rating' column with 'rating_numeric'\n",
        "df['rating_numeric'] = rating_numeric\n",
        "\n",
        "# Drop the original 'Rating' column\n",
        "df = df.drop(columns=['Rating'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059e085a",
      "metadata": {
        "id": "059e085a"
      },
      "source": [
        "# Correlation of the new input features with the new target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a018886d",
      "metadata": {
        "id": "a018886d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Randomly select 4 numeric columns (excluding the target)\n",
        "feature_cols = df.select_dtypes(include='float64').columns\n",
        "sampled_cols = random.sample(list(feature_cols), 4)\n",
        "\n",
        "# Set up 2x2 subplot grid\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "fig.suptitle('Box plot of cols with target variable', fontsize=14)\n",
        "\n",
        "# Plot each feature in a subplot\n",
        "for ax, col in zip(axes.flatten(), sampled_cols):\n",
        "    sns.boxplot(x='rating_numeric', y=col, data=df, ax=ax)\n",
        "    ax.set_title(f'{col}')\n",
        "    ax.set_xlabel('Risk Rating')\n",
        "    ax.set_ylabel(col)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for the suptitle\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beeb2867",
      "metadata": {
        "id": "beeb2867"
      },
      "source": [
        "# NLP for converting the unstructured text column with embeddings\n",
        "- A quick check on the stats of the column 'string_values' suggests that the texts are repeating and there are only 5 unique text statments. This may be as the data is artifical and does not cover the real-world data.\n",
        "- Sentiment analysis on such text may not yield good results and therefore, we will use embeddings to capture the semantics to make better use of the information.\n",
        "- There's not enough data to do topic modelling and hence it is not useful here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8529b5",
      "metadata": {
        "id": "5d8529b5"
      },
      "outputs": [],
      "source": [
        "# Basic descriptive stats\n",
        "df['string_values'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3671a31e",
      "metadata": {
        "id": "3671a31e"
      },
      "outputs": [],
      "source": [
        "# Distribution of the text data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf3e6342",
      "metadata": {
        "id": "bf3e6342"
      },
      "source": [
        "# Count of the unique values of the text data\n",
        "- Since most of the text data is neutral to positive, there is non- significant variation in the sentiment of the data and therefore sentiment analysis will not suit this data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58acec60",
      "metadata": {
        "id": "58acec60"
      },
      "outputs": [],
      "source": [
        "df['string_values'].value_counts().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f0ba654",
      "metadata": {
        "id": "9f0ba654"
      },
      "source": [
        "# Sentiment Analysis\n",
        "- By using https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english model, I have tried calculating the sentiment label and score, it doesn't have significant variation.\n",
        "    and therefore, sentiment analysis will not be useful in prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5583ad",
      "metadata": {
        "id": "5a5583ad"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load pretrained sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Example text column\n",
        "texts = df['string_values'].tolist()\n",
        "\n",
        "# Get sentiment predictions\n",
        "sentiments = sentiment_pipeline(texts)\n",
        "\n",
        "# Extract scores into DataFrame\n",
        "df['sentiment_label'] = [s['label'] for s in sentiments]\n",
        "df['sentiment_score'] = [s['score'] for s in sentiments]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "635fdf3f",
      "metadata": {
        "id": "635fdf3f"
      },
      "source": [
        "# Transformer based embeddings\n",
        "- We will load the small model 'all-MiniLM-L6-v2' to calculated the embeddings of the text.\n",
        "But since the dimension of the vector is 384, we will reduce them to 10 dimensions using PCA and scale the values\n",
        "so that they match the scale of the other features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9ed33b",
      "metadata": {
        "id": "ff9ed33b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Load model and encode\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "texts = df['string_values'].astype(str).tolist()\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "# 2. Reduce dimensionality with PCA\n",
        "n_components = 10\n",
        "pca = PCA(n_components=n_components)\n",
        "embeddings_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "# 3. Scale PCA output to range [-3, 3]\n",
        "scaler = MinMaxScaler(feature_range=(-3, 3))\n",
        "embeddings_scaled = scaler.fit_transform(embeddings_pca)\n",
        "\n",
        "# 4. Convert to DataFrame and merge back to df\n",
        "embedding_df = pd.DataFrame(embeddings_scaled, columns=[f'emb_{i+1}' for i in range(n_components)])\n",
        "df = pd.concat([df.reset_index(drop=True), embedding_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Modelling\n",
        "- Since we are dealing with credit ratings, we will use classification models to predict the ratings.\n",
        "- we have made numeric classes of ratings after mapping the original ratings to risk categories.\n",
        "- We will do GBM model training for this exercise."
      ],
      "metadata": {
        "id": "5b7a794f"
      },
      "id": "5b7a794f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0bab64",
      "metadata": {
        "id": "ad0bab64"
      },
      "outputs": [],
      "source": [
        "# starting with structured features only\n",
        "\n",
        "\n",
        "X = df[structured_cols]\n",
        "y = df['rating_numeric']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define models and hyperparameter grid\n",
        "\n",
        "models = {\n",
        "    'GBM': {\n",
        "        'model': GradientBoostingClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'LightGBM': {\n",
        "        'model': LGBMClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'num_leaves': [15, 31, 63],\n",
        "            'max_depth': [-1, 5, 10]\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "feIzMPEAOrkv"
      },
      "id": "feIzMPEAOrkv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through models and tune hyperparameters\n",
        "\n",
        "structured_results = []\n",
        "\n",
        "for name, mp in models.items():\n",
        "    print(f\"Running model: {name}\")\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        mp['model'],\n",
        "        mp['params'],\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {search.best_params_}\")\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    print(f\"Accuracy on test set for {name}: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    structured_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc\n",
        "    })\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dsB8PCQ7OsJX"
      },
      "id": "dsB8PCQ7OsJX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_results_df = pd.DataFrame(structured_results).sort_values(by='Accuracy', ascending=False)\n",
        "print(\"\\nStructured Feature Model Comparison:\")\n",
        "print(structured_results_df)"
      ],
      "metadata": {
        "id": "_GyP3-BDGBdj"
      },
      "id": "_GyP3-BDGBdj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now training using text-only embedding features"
      ],
      "metadata": {
        "id": "4X1j_onddi1Z"
      },
      "id": "4X1j_onddi1Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZhRFCH8fGU-"
      },
      "id": "WZhRFCH8fGU-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text embeddings features dataframe\n",
        "X_text = df[[f\"emb_{i}\" for i in range(1, 11)]]\n",
        "y = df['rating_numeric']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x8nUFInhdLWz"
      },
      "id": "x8nUFInhdLWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train-test split\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
        "    X_text, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "SyQP47YKd2Lv"
      },
      "id": "SyQP47YKd2Lv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text"
      ],
      "metadata": {
        "id": "Ho2MoXxdgWip"
      },
      "id": "Ho2MoXxdgWip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define models and hyperparameters\n",
        "models = {\n",
        "    'GBM_text': {\n",
        "        'model': GradientBoostingClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'LightGBM_text': {\n",
        "        'model': LGBMClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'num_leaves': [15, 31, 63],\n",
        "            'max_depth': [-1, 5, 10]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "9F6DEayhdKAr"
      },
      "id": "9F6DEayhdKAr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train, tune and evaluate\n",
        "text_results = []\n",
        "\n",
        "for name, mp in models.items():\n",
        "    print(f\"\\nTraining {name} on text features...\")\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=mp['model'],\n",
        "        param_distributions=mp['params'],\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    search.fit(X_train_text, y_train_text)\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    print(f\"Best params for {name}: {search.best_params_}\")\n",
        "\n",
        "    y_pred_text = best_model.predict(X_test_text)\n",
        "\n",
        "    accuracy_text = accuracy_score(y_test_text, y_pred_text)\n",
        "\n",
        "    print(f\"Accuracy for {name}: {accuracy_text:.4f}\")\n",
        "    print(classification_report(y_test_text, y_pred_text))\n",
        "\n",
        "    text_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_text\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "LkF02wfHeQuw"
      },
      "id": "LkF02wfHeQuw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Summary\n",
        "text_results_df = pd.DataFrame(text_results).sort_values(by='Accuracy', ascending=False)\n",
        "print(\"\\nText Feature Model Comparison:\")\n",
        "print(text_results_df)"
      ],
      "metadata": {
        "id": "suoSbgIMeSh6"
      },
      "id": "suoSbgIMeSh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now train model with structured and text columns"
      ],
      "metadata": {
        "id": "MiuqXAlgrWPD"
      },
      "id": "MiuqXAlgrWPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Combine structured + text features\n",
        "X_combined = pd.concat([X, X_text], axis=1)\n",
        "\n",
        "# Step 2: Train-test split\n",
        "X_train_comb, X_test_comb, y_train_comb, y_test_comb = train_test_split(\n",
        "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Define models and hyperparameter grids\n",
        "models = {\n",
        "    'GBM_combined': {\n",
        "        'model': GradientBoostingClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    },\n",
        "    'LightGBM_combined': {\n",
        "        'model': LGBMClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'num_leaves': [15, 31, 63],\n",
        "            'max_depth': [-1, 5, 10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 4: Train and evaluate each model\n",
        "combined_results = []\n",
        "\n",
        "for name, mp in models.items():\n",
        "    print(f\"\\nTraining {name} on combined features...\")\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=mp['model'],\n",
        "        param_distributions=mp['params'],\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    search.fit(X_train_comb, y_train_comb)\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    print(f\"Best parameters for {name}: {search.best_params_}\")\n",
        "\n",
        "    y_pred = best_model.predict(X_test_comb)\n",
        "\n",
        "    acc = accuracy_score(y_test_comb, y_pred)\n",
        "    print(f\"Accuracy on test set: {acc:.4f}\")\n",
        "    print(classification_report(y_test_comb, y_pred))\n",
        "\n",
        "    combined_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc\n",
        "    })\n",
        "\n",
        "# Step 5: Summary table\n",
        "combined_results_df = pd.DataFrame(combined_results).sort_values(by='Accuracy', ascending=False)\n",
        "print(\"\\Combined Feature Model Comparison:\")\n",
        "print(combined_results_df)\n"
      ],
      "metadata": {
        "id": "yTlVFiPnsV5S"
      },
      "id": "yTlVFiPnsV5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create confusion matrix based on the combined data\n",
        "- since the overall data size is jsut 100 rows, the training data is not enough to train the model. As a result, we can see the model is not able to predict the right class for different class ratings."
      ],
      "metadata": {
        "id": "gKaEscCGTR6i"
      },
      "id": "gKaEscCGTR6i"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test_comb, y_pred)\n",
        "\n",
        "# Display it\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "03zb5ie4TVUb"
      },
      "id": "03zb5ie4TVUb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison Report of the performance of models across structured only, text only and combined features\n"
      ],
      "metadata": {
        "id": "8QC8PpRTFfPf"
      },
      "id": "8QC8PpRTFfPf"
    },
    {
      "cell_type": "code",
      "source": [
        "structured_results_df['DataType'] = 'Structured'\n",
        "text_results_df['DataType'] = 'Text'\n",
        "combined_results_df['DataType'] = 'Combined'\n",
        "\n",
        "performance_df = pd.concat([\n",
        "    structured_results_df,\n",
        "    text_results_df,\n",
        "    combined_results_df\n",
        "], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "lAwxeW1IJPI2"
      },
      "id": "lAwxeW1IJPI2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the performance\n",
        "- We can see the performance of the GBM model has increased after considering the unstructured text into the model."
      ],
      "metadata": {
        "id": "XD9Md4_4JbVi"
      },
      "id": "XD9Md4_4JbVi"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=performance_df, x='Model', y='Accuracy', hue='DataType')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wKqw982YJdjx"
      },
      "id": "wKqw982YJdjx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SHAP analysis\n",
        "- side by side view of which features impact different rating classes"
      ],
      "metadata": {
        "id": "W6Z1oUiORCav"
      },
      "id": "W6Z1oUiORCav"
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importance using SHAP\n",
        "\n",
        "# Using GBM for the combined data\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "shap_values = explainer.shap_values(X_combined)\n",
        "\n",
        "\n",
        "# Plot summary\n",
        "shap.summary_plot(shap_values, X_combined, plot_type=\"bar\")\n"
      ],
      "metadata": {
        "id": "EcWj8chiJd4t"
      },
      "id": "EcWj8chiJd4t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qdq309aTP73a"
      },
      "id": "Qdq309aTP73a"
    },
    {
      "cell_type": "code",
      "source": [
        "# comment"
      ],
      "metadata": {
        "id": "jPVyV98yWmAS"
      },
      "id": "jPVyV98yWmAS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance by each class type of the rating\n",
        "- The rating of low risk class doesn't have much impact from the leverage ratios while the high risk classes does have more impact from the leverage ratios. This confirms the trend that is usaully scene in the real world."
      ],
      "metadata": {
        "id": "UMJndboAReiV"
      },
      "id": "UMJndboAReiV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split shap values by class\n",
        "shap_values_by_class = [shap_values[:, :, i] for i in range(shap_values.shape[2])]\n",
        "\n",
        "# Plot for class 0\n",
        "shap.summary_plot(shap_values_by_class[0], X_combined, plot_type='bar')"
      ],
      "metadata": {
        "id": "he3DB9CTN643"
      },
      "id": "he3DB9CTN643",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkwRq40MS2zx"
      },
      "id": "zkwRq40MS2zx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcO6dhuUS2BP"
      },
      "id": "lcO6dhuUS2BP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa47be74",
      "metadata": {
        "id": "aa47be74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad08498",
      "metadata": {
        "id": "2ad08498"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadf094f",
      "metadata": {
        "id": "cadf094f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}